import { existsSync, mkdirSync, readFileSync, writeFileSync } from "fs";
import { homedir } from "os";
import { dirname, join } from "path";
import { spawn } from "child_process";
import { CLI_USER_AGENT, getLlmKey, getLlmUrl } from "../lib/config.js";
import * as output from "../lib/output.js";
/**
 * Fallback model catalog — used when the gateway is unreachable or unauthenticated.
 * resolveModels() fetches live data from GET /v1/models; this list is the offline safety net.
 */
const GATEWAY_MODELS = [
    // Claude — 90% cache read discount, 25% cache write premium
    {
        id: "claude-opus-4.6",
        name: "Claude Opus 4.6",
        owned_by: "anthropic",
        cost: { input: 15.0, output: 75.0, cacheRead: 1.5, cacheWrite: 18.75 },
    },
    {
        id: "claude-opus-4.5",
        name: "Claude Opus 4.5",
        owned_by: "anthropic",
        cost: { input: 15.0, output: 75.0, cacheRead: 1.5, cacheWrite: 18.75 },
    },
    {
        id: "claude-sonnet-4.5",
        name: "Claude Sonnet 4.5",
        owned_by: "anthropic",
        cost: { input: 3.0, output: 15.0, cacheRead: 0.3, cacheWrite: 3.75 },
    },
    {
        id: "claude-haiku-4.5",
        name: "Claude Haiku 4.5",
        owned_by: "anthropic",
        cost: { input: 0.8, output: 4.0, cacheRead: 0.08, cacheWrite: 1.0 },
    },
    // Gemini — 75% cache read discount
    {
        id: "gemini-3-pro",
        name: "Gemini 3 Pro",
        owned_by: "google",
        cost: { input: 1.25, output: 10.0, cacheRead: 0.3125, cacheWrite: 1.25 },
    },
    {
        id: "gemini-3-flash",
        name: "Gemini 3 Flash",
        owned_by: "google",
        cost: { input: 0.15, output: 0.6, cacheRead: 0.0375, cacheWrite: 0.15 },
    },
    {
        id: "gemini-2.5-pro",
        name: "Gemini 2.5 Pro",
        owned_by: "google",
        cost: { input: 1.25, output: 10.0, cacheRead: 0.3125, cacheWrite: 1.25 },
    },
    {
        id: "gemini-2.5-flash",
        name: "Gemini 2.5 Flash",
        owned_by: "google",
        cost: { input: 0.15, output: 0.6, cacheRead: 0.0375, cacheWrite: 0.15 },
    },
    // OpenAI — 50% cache read discount
    {
        id: "gpt-5.2",
        name: "GPT 5.2",
        owned_by: "openai",
        cost: { input: 2.5, output: 10.0, cacheRead: 1.25, cacheWrite: 2.5 },
    },
    {
        id: "gpt-5.2-codex",
        name: "GPT 5.2 Codex",
        owned_by: "openai",
        cost: { input: 2.5, output: 10.0, cacheRead: 1.25, cacheWrite: 2.5 },
    },
    {
        id: "gpt-5-mini",
        name: "GPT 5 Mini",
        owned_by: "openai",
        cost: { input: 0.4, output: 1.6, cacheRead: 0.2, cacheWrite: 0.4 },
    },
    {
        id: "gpt-5-nano",
        name: "GPT 5 Nano",
        owned_by: "openai",
        cost: { input: 0.1, output: 0.4, cacheRead: 0.05, cacheWrite: 0.1 },
    },
    // Other providers
    {
        id: "kimi-k2.5",
        name: "Kimi K2.5",
        owned_by: "moonshotai",
        cost: { input: 0.6, output: 2.4, cacheRead: 0.09, cacheWrite: 0.6 },
    },
    {
        id: "qwen3-coder",
        name: "Qwen3 Coder",
        owned_by: "qwen",
        cost: { input: 0.3, output: 1.2, cacheRead: 0.15, cacheWrite: 0.3 },
    },
];
/** Fetch live model list from the gateway; falls back to hardcoded catalog. */
async function resolveModels() {
    const llmKey = getLlmKey();
    if (!llmKey)
        return { models: GATEWAY_MODELS, live: false };
    try {
        const res = await fetch(`${getLlmUrl()}/v1/models`, {
            headers: { "X-API-Key": llmKey, "User-Agent": CLI_USER_AGENT },
            signal: AbortSignal.timeout(5000),
        });
        if (!res.ok)
            return { models: GATEWAY_MODELS, live: false };
        const body = (await res.json());
        const models = body.data.map((m) => {
            const fallback = GATEWAY_MODELS.find((g) => g.id === m.id);
            return {
                id: m.id,
                name: m.name ?? fallback?.name ?? m.id,
                owned_by: m.owned_by,
                cost: m.pricing
                    ? {
                        input: m.pricing.input,
                        output: m.pricing.output,
                        cacheRead: m.pricing.cache_read,
                        cacheWrite: m.pricing.cache_write,
                    }
                    : (fallback?.cost ?? {
                        input: 0,
                        output: 0,
                        cacheRead: 0,
                        cacheWrite: 0,
                    }),
            };
        });
        return { models, live: true };
    }
    catch {
        return { models: GATEWAY_MODELS, live: false };
    }
}
/* ─────────────────────── Shared helpers ──────────────────────────────────── */
function warnIfNoKey(key) {
    if (!key) {
        console.log();
        output.warn("No API key configured. Set BANKR_API_KEY (or BANKR_LLM_KEY) or run: bankr login");
    }
}
/**
 * Read a JSON config file, merge in new data, and write it back.
 * Creates parent directories as needed. Preserves existing keys.
 */
function installConfigFile(configFile, toolName, merge) {
    const configDir = dirname(configFile);
    let existing = {};
    if (existsSync(configFile)) {
        try {
            existing = JSON.parse(readFileSync(configFile, "utf-8"));
        }
        catch {
            output.warn(`Could not parse existing ${toolName} config — creating fresh`);
        }
    }
    merge(existing);
    if (!existsSync(configDir)) {
        mkdirSync(configDir, { recursive: true });
    }
    writeFileSync(configFile, JSON.stringify(existing, null, 2) + "\n", "utf-8");
    output.success(`Bankr provider installed to ${configFile}`);
}
/* ───────────────────────────── bankr llm models ───────────────────────────── */
export async function modelsCommand() {
    const spin = output.spinner("Fetching models…");
    const { models, live } = await resolveModels();
    spin.stop();
    output.brandBold("Bankr LLM Gateway — Available Models");
    console.log();
    const COL = { id: 24, name: 24, provider: 12 };
    console.log(`  ${output.fmt.brandBold("Model ID".padEnd(COL.id))} ${output.fmt.brandBold("Name".padEnd(COL.name))} ${output.fmt.brandBold("Provider")}`);
    console.log(output.fmt.dim(`  ${"─".repeat(COL.id + COL.name + COL.provider + 2)}`));
    for (const m of models) {
        console.log(`  ${output.fmt.brand(m.id.padEnd(COL.id))} ${m.name.padEnd(COL.name)} ${output.fmt.dim(m.owned_by)}`);
    }
    console.log();
    output.dim(`  Gateway: ${getLlmUrl()}`);
    output.dim(`  ${models.length} models available${live ? "" : " (cached)"}`);
}
/* ─────────────────────── bankr llm credits ─────────────────────────────────── */
export async function creditsCommand() {
    const llmKey = getLlmKey();
    if (!llmKey) {
        output.error("Not authenticated. Run `bankr login` first.");
        process.exit(1);
    }
    const llmUrl = getLlmUrl();
    const spin = output.spinner("Fetching credit balance…");
    try {
        const res = await fetch(`${llmUrl}/v1/credits`, {
            headers: { "X-API-Key": llmKey, "User-Agent": CLI_USER_AGENT },
            signal: AbortSignal.timeout(10000),
        });
        spin.stop();
        if (res.status === 402) {
            output.brandBold("Bankr LLM Gateway — Credits");
            console.log();
            output.label("Credit Balance", "$0.00");
            console.log();
            output.warn("Credits exhausted. No LLM Gateway requests can be made.");
            return;
        }
        if (res.status === 401 || res.status === 403) {
            output.error("Authentication failed. Check your API key or run: bankr login");
            process.exit(1);
        }
        if (!res.ok) {
            output.error(`Failed to fetch credits (HTTP ${res.status})`);
            process.exit(1);
        }
        const body = (await res.json());
        output.brandBold("Bankr LLM Gateway — Credits");
        console.log();
        output.label("Credit Balance", `$${body.balanceUsd.toFixed(2)}`);
        console.log();
        output.dim(`  Gateway: ${llmUrl}`);
    }
    catch (err) {
        spin.stop();
        output.error(`Failed to fetch credits: ${err.message}`);
        process.exit(1);
    }
}
/* ──────────────────────── bankr llm setup openclaw ────────────────────────── */
export async function setupOpenclawCommand(opts) {
    const llmKey = getLlmKey();
    const llmUrl = getLlmUrl();
    const { models } = await resolveModels();
    const providerConfig = {
        baseUrl: llmUrl,
        apiKey: llmKey ?? "${BANKR_API_KEY}",
        api: "openai-completions",
        models: models.map((m) => ({
            id: m.id,
            name: m.name,
            ...(m.owned_by === "anthropic" ? { api: "anthropic-messages" } : {}),
            cost: m.cost,
        })),
    };
    if (opts.install) {
        const configFile = join(homedir(), ".openclaw", "openclaw.json");
        installConfigFile(configFile, "OpenClaw", function (existing) {
            const models = existing.models ?? {};
            const providers = models.providers ?? {};
            providers.bankr = providerConfig;
            models.providers = providers;
            existing.models = models;
        });
        warnIfNoKey(llmKey);
        return;
    }
    console.log(JSON.stringify({ models: { providers: { bankr: providerConfig } } }, null, 2));
    console.log();
    if (!llmKey) {
        output.warn("No API key set. Replace ${BANKR_API_KEY} with your key or run: bankr login");
    }
    output.dim("Add to ~/.openclaw/openclaw.json or run: bankr llm setup openclaw --install");
}
/* ──────────────────────── bankr llm setup opencode ─────────────────────────── */
export async function setupOpenCodeCommand(opts) {
    const llmKey = getLlmKey();
    const llmUrl = getLlmUrl();
    const { models } = await resolveModels();
    const modelsObj = {};
    for (const m of models) {
        modelsObj[m.id] = { name: m.name };
    }
    const bankrProvider = {
        npm: "@ai-sdk/openai-compatible",
        name: "Bankr LLM Gateway",
        options: {
            baseURL: `${llmUrl}/v1`,
            apiKey: llmKey ?? "{env:BANKR_API_KEY}",
        },
        models: modelsObj,
    };
    const SCHEMA_URL = "https://opencode.ai/config.json";
    if (opts.install) {
        const configFile = join(homedir(), ".config", "opencode", "opencode.json");
        installConfigFile(configFile, "OpenCode", function (existing) {
            const providers = existing.provider ?? {};
            providers.bankr = bankrProvider;
            existing.provider = providers;
            existing.$schema ?? (existing.$schema = SCHEMA_URL);
        });
        warnIfNoKey(llmKey);
        return;
    }
    const fullConfig = {
        $schema: SCHEMA_URL,
        provider: { bankr: bankrProvider },
    };
    console.log(JSON.stringify(fullConfig, null, 2));
    console.log();
    if (!llmKey) {
        output.warn("No API key set. Set BANKR_API_KEY env var or run: bankr login");
    }
    output.dim("Add to ~/.config/opencode/opencode.json or run: bankr llm setup opencode --install");
    output.dim("Use bankr/ prefix for models: opencode -m bankr/claude-opus-4.6");
}
/* ──────────────────────── bankr llm setup cursor ──────────────────────────── */
export async function setupCursorCommand() {
    const llmKey = getLlmKey();
    const llmUrl = getLlmUrl();
    const token = llmKey ?? "<your-bankr-api-key>";
    const { models } = await resolveModels();
    // Pick one model per provider as recommended examples
    const recommendedIds = ["claude-opus-4.6", "gemini-3-pro", "gpt-5.2"];
    const recommended = recommendedIds.filter((id) => models.some((m) => m.id === id));
    output.brandBold("Cursor — Bankr LLM Gateway");
    console.log();
    output.info("In Cursor, go to Settings > Models and configure:");
    console.log();
    console.log(`  1. Enter your API key under ${output.fmt.brand("OpenAI API Key")}:`);
    console.log(`     ${token}`);
    console.log();
    console.log(`  2. Enable ${output.fmt.brand("Override OpenAI Base URL")} and set:`);
    console.log(`     ${llmUrl}/v1`);
    console.log();
    console.log(`  3. Click ${output.fmt.brand("+ Add model")} and add the models you want:`);
    for (const id of recommended) {
        console.log(`     ${output.fmt.dim("•")} ${id}`);
    }
    console.log(`     ${output.fmt.dim("(see full list: bankr llm models)")}`);
    warnIfNoKey(llmKey);
    console.log();
    output.warn("When Override Base URL is enabled, ALL model requests go through the gateway.");
    output.dim("Disable other models you don't need to avoid validation errors.");
}
/* ─────────────────────── bankr llm setup claude-code ──────────────────────── */
export async function setupClaudeCodeCommand() {
    const llmKey = getLlmKey();
    const llmUrl = getLlmUrl();
    const token = llmKey ?? "<your-bankr-api-key>";
    output.brandBold("Claude Code — Bankr LLM Gateway");
    console.log();
    output.info("Add to your shell profile (~/.zshrc, ~/.bashrc):");
    console.log();
    console.log(`  export ANTHROPIC_BASE_URL="${llmUrl}"`);
    console.log(`  export ANTHROPIC_AUTH_TOKEN="${token}"`);
    warnIfNoKey(llmKey);
    console.log();
    output.dim("All Claude Code requests will route through the Bankr gateway.");
    output.dim("Or launch directly: bankr llm claude");
}
/* ─────────────────────── Shared launcher helpers ────────────────────────── */
function requireAuth() {
    const llmKey = getLlmKey();
    if (!llmKey) {
        output.error("Not authenticated. Run `bankr login` first.");
        process.exit(1);
    }
    return llmKey;
}
function launchTool(binary, args, env, installUrl) {
    return new Promise(() => {
        const child = spawn(binary, args, {
            stdio: "inherit",
            env: { ...process.env, ...env },
        });
        child.on("error", (err) => {
            if (err.code === "ENOENT") {
                output.error(`${binary} not found. Install: ${installUrl}`);
            }
            else {
                output.error(`Failed to start ${binary}: ${err.message}`);
            }
            process.exit(1);
        });
        child.on("exit", (code) => {
            process.exit(code ?? 0);
        });
    });
}
function fileContains(filePath, search) {
    try {
        return readFileSync(filePath, "utf-8").includes(search);
    }
    catch {
        return false;
    }
}
/* ─────────────────────────── bankr llm claude ─────────────────────────────── */
export async function claudeCommand(args) {
    const llmKey = requireAuth();
    const llmUrl = getLlmUrl();
    output.dim(`Launching Claude Code via ${llmUrl}`);
    return launchTool("claude", args, { ANTHROPIC_BASE_URL: llmUrl, ANTHROPIC_AUTH_TOKEN: llmKey }, "https://docs.anthropic.com/en/docs/claude-code");
}
/* ────────────────────────── bankr llm opencode ───────────────────────────── */
export async function opencodeCommand(args) {
    const llmKey = requireAuth();
    const llmUrl = getLlmUrl();
    const configFile = join(homedir(), ".config", "opencode", "opencode.json");
    if (!existsSync(configFile) || !fileContains(configFile, `"bankr"`)) {
        await setupOpenCodeCommand({ install: true });
    }
    output.dim(`Launching OpenCode via ${llmUrl}`);
    return launchTool("opencode", args, { BANKR_API_KEY: llmKey }, "https://opencode.ai");
}
//# sourceMappingURL=llm.js.map